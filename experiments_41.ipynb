{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f8c765",
   "metadata": {},
   "source": [
    "# x0 Identifiability Analysis Pipeline\n",
    "\n",
    "This notebook executes the complete pyident workflow for analyzing how initial condition (x0) sampling strategies affect LTI system identifiability.\n",
    "\n",
    "**Pipeline stages:**\n",
    "1. Generate random controllable/uncontrollable systems (Ginibre ensemble)\n",
    "2. Filter by density regime (0.3-0.7)\n",
    "3. Sample x0 with different sparsification levels\n",
    "4. Compute PBH structural identifiability scores\n",
    "5. Visualize binary classification (identifiable vs non-identifiable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    plt = None\n",
    "\n",
    "# Import pyident modules\n",
    "from pyident.ensembles import sparse_continuous, controllability_rank\n",
    "from pyident.metrics import pbh_margin_structured\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "SEED = 12345\n",
    "M = 2  # Number of inputs\n",
    "SPARSITY_GRID = np.arange(0.0, 1.1, 0.1)\n",
    "NDIM_GRID = np.arange(2, 11, 1)\n",
    "SAMPLES_PER_POINT = 1000\n",
    "DENSITY_MIN = 0.3\n",
    "DENSITY_MAX = 0.7\n",
    "X0_DENSITIES = [0.25, 0.5, 0.75, 1.0]\n",
    "X0_SAMPLES_PER_DENSITY = 100\n",
    "PBH_THRESHOLD = 1e-6\n",
    "\n",
    "# Output directories\n",
    "ENSEMBLE_DIR = pathlib.Path(\"pyident_results/iclr_manuscript/ensemble\")\n",
    "X0_BOXPLOT_DIR = pathlib.Path(\"pyident_results/x0_boxplot\")\n",
    "\n",
    "# Create directories\n",
    "ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "X0_BOXPLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directories created:\")\n",
    "print(f\"  Ensemble: {ENSEMBLE_DIR.absolute()}\")\n",
    "print(f\"  x0 Boxplot: {X0_BOXPLOT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943ba0d",
   "metadata": {},
   "source": [
    "## Stage 1: Generate (A, B) Ensemble with Controllability Analysis\n",
    "\n",
    "Generate random LTI systems using Ginibre ensemble with sparsification, then label by controllability:\n",
    "- Vary sparsity: 0.0 → 1.0 (step 0.1)\n",
    "- Vary state dimension n: 2 → 10 (step 1)\n",
    "- Fixed m = 2 inputs, 1000 samples per grid point\n",
    "- Compute controllability rank for each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system(n: int, m: int, sparsity: float, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Generate (A, B) from sparse Ginibre ensemble.\"\"\"\n",
    "    A, B = sparse_continuous(\n",
    "        n=n,\n",
    "        m=m,\n",
    "        rng=rng,\n",
    "        which=\"both\",\n",
    "        p_density=1.0 - sparsity,  # p_density is sparsity parameter\n",
    "    )\n",
    "    return A, B\n",
    "\n",
    "def matrix_density(M: np.ndarray, tol: float = 1e-12) -> float:\n",
    "    \"\"\"Compute density of nonzero entries.\"\"\"\n",
    "    return float(np.sum(np.abs(M) > tol)) / float(M.size)\n",
    "\n",
    "# Generate ensemble\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 1: Generating (A, B) ensemble with controllability labels\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "ensemble_data = []\n",
    "system_id = 0\n",
    "\n",
    "for sparsity in SPARSITY_GRID:\n",
    "    for n in NDIM_GRID:\n",
    "        for sample in range(SAMPLES_PER_POINT):\n",
    "            A, B = generate_system(n, M, sparsity, rng)\n",
    "            \n",
    "            # Compute controllability rank\n",
    "            ctrb_rank = controllability_rank(A, B)\n",
    "            is_controllable = (ctrb_rank == n)\n",
    "            \n",
    "            # Compute densities\n",
    "            density_A = matrix_density(A)\n",
    "            density_B = matrix_density(B)\n",
    "            density_AB = matrix_density(np.hstack([A, B]))\n",
    "            \n",
    "            ensemble_data.append({\n",
    "                'system_id': system_id,\n",
    "                'sparsity': float(sparsity),\n",
    "                'n': int(n),\n",
    "                'm': int(M),\n",
    "                'ctrb_rank': int(ctrb_rank),\n",
    "                'is_controllable': bool(is_controllable),\n",
    "                'density_A': float(density_A),\n",
    "                'density_B': float(density_B),\n",
    "                'density_AB': float(density_AB),\n",
    "            })\n",
    "            system_id += 1\n",
    "            \n",
    "            # Save A, B to NPZ (we'll save all systems at once below)\n",
    "\n",
    "print(f\"Generated {len(ensemble_data)} systems\")\n",
    "print(f\"Sparsity range: {SPARSITY_GRID}\")\n",
    "print(f\"Dimension range: {NDIM_GRID}\")\n",
    "\n",
    "# Create DataFrame\n",
    "ensemble_df = pd.DataFrame(ensemble_data)\n",
    "\n",
    "# Calculate controllability statistics\n",
    "n_controllable = ensemble_df['is_controllable'].sum()\n",
    "n_uncontrollable = (~ensemble_df['is_controllable']).sum()\n",
    "print(f\"\\nControllability summary:\")\n",
    "print(f\"  Controllable: {n_controllable} ({100*n_controllable/len(ensemble_df):.1f}%)\")\n",
    "print(f\"  Uncontrollable: {n_uncontrollable} ({100*n_uncontrollable/len(ensemble_df):.1f}%)\")\n",
    "\n",
    "# Save ensemble metadata\n",
    "ensemble_csv = ENSEMBLE_DIR / \"ensemble_metadata.csv\"\n",
    "ensemble_df.to_csv(ensemble_csv, index=False)\n",
    "print(f\"\\nSaved ensemble metadata to {ensemble_csv}\")\n",
    "\n",
    "# Heatmap: uncontrollable fraction per (sparsity, ndim)\n",
    "heatmap_data = ensemble_df.groupby(['sparsity', 'n']).apply(\n",
    "    lambda g: (~g['is_controllable']).sum() / len(g)\n",
    ").unstack()\n",
    "\n",
    "print(\"\\nUncontrollable fraction heatmap (rows: n, cols: sparsity):\")\n",
    "print(heatmap_data.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59679633",
   "metadata": {},
   "source": [
    "## Stage 2: Filter Uncontrollable Systems by Density Regime\n",
    "\n",
    "Select systems with controllability rank deficit density in [0.3, 0.7], which contain mixed controllable/uncontrollable systems. Save filtered datasets as CSV (metadata) and NPZ (matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STAGE 2: Filtering systems by density regime\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Filter by density regime: keep systems with 0.3 <= rho <= 0.7\n",
    "# where rho = (n - ctrb_rank) / n is controllability rank deficit density\n",
    "ensemble_df['density'] = (ensemble_df['n'] - ensemble_df['ctrb_rank']) / ensemble_df['n']\n",
    "filtered_df = ensemble_df[\n",
    "    (ensemble_df['density'] >= DENSITY_MIN) & \n",
    "    (ensemble_df['density'] <= DENSITY_MAX)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nFiltering by density {DENSITY_MIN} <= ρ <= {DENSITY_MAX}:\")\n",
    "print(f\"  Original systems: {len(ensemble_df)}\")\n",
    "print(f\"  Filtered systems: {len(filtered_df)} ({100*len(filtered_df)/len(ensemble_df):.1f}%)\")\n",
    "\n",
    "# Show density distribution\n",
    "print(f\"\\nFiltered systems by (n, sparsity):\")\n",
    "filtered_summary = filtered_df.groupby(['n', 'sparsity']).size().unstack(fill_value=0)\n",
    "print(filtered_summary)\n",
    "\n",
    "# Save filtered dataset CSV\n",
    "filtered_csv = ENSEMBLE_DIR / \"systems_unctrb_d0.3_0.7.csv\"\n",
    "filtered_df.to_csv(filtered_csv, index=False)\n",
    "print(f\"\\nSaved filtered systems to {filtered_csv}\")\n",
    "\n",
    "# For NPZ, we need to regenerate the (A, B) matrices\n",
    "print(\"\\nReconstructing (A, B) matrices for filtered systems...\")\n",
    "rng = np.random.default_rng(SEED)\n",
    "A_list = []\n",
    "B_list = []\n",
    "row_indices = []\n",
    "\n",
    "for idx, (_, row) in enumerate(filtered_df.iterrows()):\n",
    "    sparsity = row['sparsity']\n",
    "    n = row['n']\n",
    "    \n",
    "    # Regenerate to get exact (A, B)\n",
    "    A, B = generate_system(n, M, sparsity, rng)\n",
    "    A_list.append(A)\n",
    "    B_list.append(B)\n",
    "    row_indices.append(idx)\n",
    "\n",
    "# Save to NPZ\n",
    "filtered_npz = ENSEMBLE_DIR / \"systems_unctrb_d0.3_0.7.npz\"\n",
    "np.savez(\n",
    "    filtered_npz,\n",
    "    A_list=A_list,\n",
    "    B_list=B_list,\n",
    "    indices=np.array(row_indices),\n",
    ")\n",
    "print(f\"Saved matrices to {filtered_npz}\")\n",
    "\n",
    "print(f\"\\nFiltered dataset ready for x0 analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16fb83",
   "metadata": {},
   "source": [
    "## Stage 3: Sample x0 with Different Sparsification Levels\n",
    "\n",
    "For each filtered (A, B) system, generate multiple x0 initial conditions using Bernoulli sparsification:\n",
    "- x0_density=1.0: uniform sampling from unit sphere\n",
    "- x0_density<1.0: sphere + Bernoulli mask + renormalization\n",
    "- Compute PBH structural identifiability margin for each (A, B, x0) triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00749ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unit_sphere(n: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Uniform sample on unit sphere S^{n-1}.\"\"\"\n",
    "    v = rng.standard_normal(n)\n",
    "    nrm = float(np.linalg.norm(v))\n",
    "    return v / (nrm if nrm > 0.0 else 1.0)\n",
    "\n",
    "def sample_x0(n: int, rng: np.random.Generator, x0_density: float) -> np.ndarray:\n",
    "    \"\"\"Sample x0 with Bernoulli sparsification.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Dimension\n",
    "    rng : np.random.Generator\n",
    "        RNG\n",
    "    x0_density : float\n",
    "        Keep probability. 1.0 = no sparsification\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Sampled x0 on unit sphere with sparsification applied\n",
    "    \"\"\"\n",
    "    x0 = sample_unit_sphere(n, rng)\n",
    "    \n",
    "    if x0_density < 1.0:\n",
    "        # Bernoulli sparsification: keep each entry with prob x0_density\n",
    "        mask = rng.random(n) < x0_density\n",
    "        x0 = x0 * mask\n",
    "        \n",
    "        # Renormalize to unit norm\n",
    "        nrm = float(np.linalg.norm(x0))\n",
    "        if nrm > 1e-15:\n",
    "            x0 = x0 / nrm\n",
    "    \n",
    "    return x0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 3: Computing PBH scores for x0 samples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load matrices from NPZ\n",
    "data = np.load(filtered_npz, allow_pickle=True)\n",
    "A_list = data['A_list']\n",
    "B_list = data['B_list']\n",
    "\n",
    "print(f\"\\nLoaded {len(A_list)} systems from filtered dataset\")\n",
    "\n",
    "# Compute PBH scores\n",
    "scores_data = []\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "for sys_idx, (A, B) in enumerate(zip(A_list, B_list)):\n",
    "    n = A.shape[0]\n",
    "    m = B.shape[1]\n",
    "    \n",
    "    # Get system metadata from filtered_df\n",
    "    sys_meta = filtered_df.iloc[sys_idx]\n",
    "    \n",
    "    for x0_density in X0_DENSITIES:\n",
    "        for sample_idx in range(X0_SAMPLES_PER_DENSITY):\n",
    "            # Sample x0\n",
    "            x0 = sample_x0(n, rng, x0_density)\n",
    "            \n",
    "            # Compute PBH margin\n",
    "            pbh_score = pbh_margin_structured(A, B, x0)\n",
    "            \n",
    "            # Format density label\n",
    "            x0_density_label = f\"{x0_density:.2f}\"\n",
    "            \n",
    "            scores_data.append({\n",
    "                'pbh': float(pbh_score),\n",
    "                'x0_density': float(x0_density),\n",
    "                'x0_density_label': x0_density_label,\n",
    "                'n': int(n),\n",
    "                'm': int(m),\n",
    "                'system_index': int(sys_idx),\n",
    "                'sparsity': float(sys_meta['sparsity']),\n",
    "                'is_controllable': bool(sys_meta['is_controllable']),\n",
    "                'density_AB': float(sys_meta['density_AB']),\n",
    "            })\n",
    "\n",
    "print(f\"Computed {len(scores_data)} PBH scores\")\n",
    "\n",
    "# Create scores DataFrame\n",
    "scores_df = pd.DataFrame(scores_data)\n",
    "\n",
    "# Save scores\n",
    "scores_csv = X0_BOXPLOT_DIR / \"pbh_scores.csv\"\n",
    "scores_df.to_csv(scores_csv, index=False)\n",
    "print(f\"Saved PBH scores to {scores_csv}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nPBH score summary by x0_density:\")\n",
    "summary = scores_df.groupby('x0_density')['pbh'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
    "print(summary.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff192e",
   "metadata": {},
   "source": [
    "## Stage 4: Visualize Binary Classification by x0 Sparsification\n",
    "\n",
    "Plot fraction of identifiable systems (PBH score > ε) for each x0 sparsification level using bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STAGE 4: Binary classification and visualization\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply threshold\n",
    "scores_df['is_identifiable'] = scores_df['pbh'] > PBH_THRESHOLD\n",
    "\n",
    "# Binary statistics\n",
    "binary_stats = scores_df.groupby('x0_density_label').agg({\n",
    "    'is_identifiable': ['sum', 'count', 'mean']\n",
    "}).round(4)\n",
    "binary_stats.columns = ['identifiable_count', 'total_count', 'fraction_identifiable']\n",
    "print(\"\\nBinary classification (PBH > 1e-6):\")\n",
    "print(binary_stats)\n",
    "\n",
    "# Create visualization\n",
    "if plt is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar plot: fraction identifiable\n",
    "    x0_density_labels = ['0.25', '0.50', '0.75', '1.00']\n",
    "    fractions = []\n",
    "    counts = []\n",
    "    \n",
    "    for label in x0_density_labels:\n",
    "        mask = scores_df['x0_density_label'] == label\n",
    "        frac = scores_df[mask]['is_identifiable'].mean()\n",
    "        count = scores_df[mask]['is_identifiable'].sum()\n",
    "        fractions.append(frac)\n",
    "        counts.append(count)\n",
    "    \n",
    "    # Bar plot 1: Fraction identifiable\n",
    "    bars = ax1.bar(x0_density_labels, fractions, color=(32/255, 143/255, 140/255), alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax1.set_ylabel('Fraction Identifiable', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('x0 Sparsification Density', fontsize=14, fontweight='bold')\n",
    "    ax1.set_title('Binary Classification: Identifiable vs Non-identifiable', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylim([0, 1.05])\n",
    "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'n={int(count)}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    # Box plot 2: Continuous PBH scores\n",
    "    data_by_density = [scores_df[scores_df['x0_density_label'] == label]['pbh'].values \n",
    "                       for label in x0_density_labels]\n",
    "    bp = ax2.boxplot(data_by_density, labels=x0_density_labels, patch_artist=True)\n",
    "    \n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor((32/255, 143/255, 140/255))\n",
    "        patch.set_alpha(0.8)\n",
    "    \n",
    "    for median in bp['medians']:\n",
    "        median.set_linewidth(3.0)\n",
    "        median.set_color('black')\n",
    "    \n",
    "    ax2.axhline(y=PBH_THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'ε={PBH_THRESHOLD:.0e}')\n",
    "    ax2.set_ylabel('PBH Structural Identifiability Margin', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('x0 Sparsification Density', fontsize=14, fontweight='bold')\n",
    "    ax2.set_title('Continuous Score Distribution', fontsize=16, fontweight='bold')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = X0_BOXPLOT_DIR / \"pbh_binary_classification.png\"\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\nSaved visualization to {fig_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Matplotlib not available, skipping visualization\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  Ensemble metadata: {ensemble_csv}\")\n",
    "print(f\"  Filtered systems (CSV): {filtered_csv}\")\n",
    "print(f\"  Filtered systems (NPZ): {filtered_npz}\")\n",
    "print(f\"  PBH scores (CSV): {scores_csv}\")\n",
    "print(f\"  Visualization (PNG): {fig_path if plt else 'N/A'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
